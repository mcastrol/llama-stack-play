{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLama Stack Client "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use this as a scratchpad to play with the LLama Stack Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://0.0.0.0:8321/v1/models \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">identifier</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'all-MiniLM-L6-v2'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'embedding_dimension'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">384.0</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">api_model_type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'embedding'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">provider_id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'ollama'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">provider_resource_id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'all-minilm:latest'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">model_type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'embedding'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">identifier</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'llama3.2:3b-instruct-fp16'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">api_model_type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'llm'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">provider_id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'ollama'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">provider_resource_id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'llama3.2:3b-instruct-fp16'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">model_type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'llm'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33midentifier\u001b[0m=\u001b[32m'all-MiniLM-L6-v2'\u001b[0m,\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'embedding_dimension'\u001b[0m: \u001b[1;36m384.0\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mapi_model_type\u001b[0m=\u001b[32m'embedding'\u001b[0m,\n",
       "        \u001b[33mprovider_id\u001b[0m=\u001b[32m'ollama'\u001b[0m,\n",
       "        \u001b[33mtype\u001b[0m=\u001b[32m'model'\u001b[0m,\n",
       "        \u001b[33mprovider_resource_id\u001b[0m=\u001b[32m'all-minilm:latest'\u001b[0m,\n",
       "        \u001b[33mmodel_type\u001b[0m=\u001b[32m'embedding'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33midentifier\u001b[0m=\u001b[32m'llama3.2:3b-instruct-fp16'\u001b[0m,\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mapi_model_type\u001b[0m=\u001b[32m'llm'\u001b[0m,\n",
       "        \u001b[33mprovider_id\u001b[0m=\u001b[32m'ollama'\u001b[0m,\n",
       "        \u001b[33mtype\u001b[0m=\u001b[32m'model'\u001b[0m,\n",
       "        \u001b[33mprovider_resource_id\u001b[0m=\u001b[32m'llama3.2:3b-instruct-fp16'\u001b[0m,\n",
       "        \u001b[33mmodel_type\u001b[0m=\u001b[32m'llm'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import rich\n",
    "from llama_stack_client import LlamaStackClient\n",
    "\n",
    "client = LlamaStackClient(base_url=\"http://0.0.0.0:8321\")\n",
    "models = client.models.list()\n",
    "rich.print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://0.0.0.0:8321/v1/inference/chat-completion \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletionResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">completion_message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Here is a short poem about a llama:\\n\\nWith soft fur and gentle eyes so bright,\\nThe llama roams, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">a peaceful sight.'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">stop_reason</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'end_of_turn'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">logprobs</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">metrics</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Metric</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">metric</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">value</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">unit</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Metric</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">metric</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">value</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">37.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">unit</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Metric</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">metric</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">value</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">67.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">unit</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mChatCompletionResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mcompletion_message\u001b[0m=\u001b[1;35mCompletionMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mcontent\u001b[0m=\u001b[32m'Here is a short poem about a llama:\\n\\nWith soft fur and gentle eyes so bright,\\nThe llama roams, \u001b[0m\n",
       "\u001b[32ma peaceful sight.'\u001b[0m,\n",
       "        \u001b[33mrole\u001b[0m=\u001b[32m'assistant'\u001b[0m,\n",
       "        \u001b[33mstop_reason\u001b[0m=\u001b[32m'end_of_turn'\u001b[0m,\n",
       "        \u001b[33mtool_calls\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[33mlogprobs\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mmetrics\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mMetric\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmetric\u001b[0m=\u001b[32m'prompt_tokens'\u001b[0m, \u001b[33mvalue\u001b[0m=\u001b[1;36m30\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33munit\u001b[0m=\u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mMetric\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmetric\u001b[0m=\u001b[32m'completion_tokens'\u001b[0m, \u001b[33mvalue\u001b[0m=\u001b[1;36m37\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33munit\u001b[0m=\u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mMetric\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmetric\u001b[0m=\u001b[32m'total_tokens'\u001b[0m, \u001b[33mvalue\u001b[0m=\u001b[1;36m67\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33munit\u001b[0m=\u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = client.inference.chat_completion(\n",
    "    model_id=\"llama3.2:3b-instruct-fp16\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a friendly assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Write a two-sentence poem about llama.\"},\n",
    "    ],\n",
    ")\n",
    "rich.print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama-stack-play",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
